<%@ jet
imports="
org.talend.core.model.process.INode
org.talend.core.model.process.ElementParameterParser
org.talend.core.model.metadata.IMetadataTable
org.talend.core.model.metadata.IMetadataColumn
org.talend.core.model.process.IConnection
org.talend.core.model.process.IConnectionCategory
org.talend.designer.codegen.config.CodeGeneratorArgument
org.talend.core.model.metadata.types.JavaTypesManager
org.talend.core.model.metadata.types.JavaType
org.talend.designer.runprocess.ProcessorUtilities
org.talend.designer.runprocess.ProcessorException
java.util.List 
java.util.Map
"
%>

<%
	CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
	INode node = (INode)codeGenArgument.getArgument();	
	String cid = node.getUniqueName();
	boolean isLog4jEnabled = ("true").equals(ElementParameterParser.getValue(node.getProcess(), "__LOG4J_ACTIVATE__"));
	String processId = node.getProcess().getId();
	String sparkMode = ElementParameterParser.getValue(node, "__SPARK_MODE__");
	String sparkVersion = ElementParameterParser.getValue(node, "__SPARK_VERSION__");
	boolean isStreaming = "true".equals(ElementParameterParser.getValue(node, "__STREAMING__"));
	String batchSize = ElementParameterParser.getValue(node, "__STREAMING_BATCH_SIZE__");
	List<Map<String, String>> sparkAdvancedProperties = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__SPARK_ADVANCED_PROPERTIES__");
	String sparkAppName = "\"TalendSpark_"+cid+"\"";
	
	boolean useLocalMode = "LOCAL".equals(sparkMode);
	boolean useStandaloneMode = "CLUSTER".equals(sparkMode);
	boolean useYarnClientMode = "YARN_CLIENT".equals(sparkMode);
	
	java.util.List<String> jarsToRegister = null;
	
%>

	org.apache.spark.SparkConf conf_<%=cid%> = new  org.apache.spark.SparkConf();
	conf_<%=cid%>.setAppName(<%=sparkAppName%>);
<%
	for(Map<String, String> property : sparkAdvancedProperties){
%>
		conf_<%=cid%>.set(<%=property.get("PROPERTY")%>, <%=property.get("VALUE")%>);
<%		
	}
	
	String master = "\"local[*]\"";
	if(useStandaloneMode) {
		master = ElementParameterParser.getValue(node, "__SPARK_HOST__");
	}
	
	if(useYarnClientMode) {
		master = "\"yarn-client\"";
	}
%>
	conf_<%=cid%>.setMaster(<%=master%>);
<%	
	if(!useLocalMode) { // If the spark mode is not local.
		if(useStandaloneMode) {
			String sparkHome = ElementParameterParser.getValue(node, "__SPARK_HOME__");
			boolean defineDriverHost = "true".equals(ElementParameterParser.getValue(node, "__DEFINE_SPARK_DRIVER_HOST__"));
			if(defineDriverHost) {
                String driverHost = ElementParameterParser.getValue(node, "__SPARK_DRIVER_HOST__");
                if(driverHost != null && !"".equals(driverHost)) {
%>
                    conf_<%=cid%>.set("spark.driver.host", <%=driverHost%>);
<%
                }
			}
%>
			conf_<%=cid%>.setSparkHome(<%=sparkHome%>);
<%
		}
		String[] commandLine = new String[] {"<command>"};
		try {
			commandLine = ProcessorUtilities.getCommandLine("win32",true, processId, "",org.talend.designer.runprocess.IProcessor.NO_STATISTICS,org.talend.designer.runprocess.IProcessor.NO_TRACES, new String[]{});
		} catch (ProcessorException e) {
			e.printStackTrace();
		}
		
		java.util.List<String> jars = new java.util.ArrayList<String>();
		jarsToRegister = new java.util.ArrayList<String>();
		int commandLineLength = commandLine.length;

		for (int i = 0; i < commandLineLength; i++) {
			if(commandLine[i].contains("-cp")) {
				if(commandLineLength > i + 1) {
					jars = java.util.Arrays.asList(commandLine[i+1].split(";"));
				}
				break;
			}
		}
%>
		<%@ include file="@{org.talend.designer.components.localprovider}/components/templates/GetJarsToRegister.javajet"%>
<%
		boolean hasClasses = false;
		java.util.List<java.io.File> functionsList = null;
		java.util.List<java.io.File> routinesList = null;
		for(int j = 0; j < jars.size(); j++) {
			if(jars.get(j).contains("/classes")) {
				hasClasses = true;
%>
				class ZipUtils_<%=cid%> {
					public String zipFile(String jarName, java.util.List<String> fileList, String packageFolder) throws java.lang.Exception {
						String tmp = System.getProperty("java.io.tmpdir").replaceAll("\\\\", "/");
						java.util.zip.ZipOutputStream zos = new java.util.zip.ZipOutputStream(new java.io.FileOutputStream(tmp + "/" + jarName));
						java.io.FileInputStream fis = null;
						byte[] bytes;
						int length;
						for(String file : fileList) {
							zos.putNextEntry(new java.util.zip.ZipEntry(packageFolder + "/" + file.substring(file.lastIndexOf("/") + 1, file.length())));
							try {
								fis = new java.io.FileInputStream(file);
							} catch (java.lang.Exception e) {
								throw e;
							}

							bytes = new byte[1024];
							while ((length = fis.read(bytes)) >= 0) {
								zos.write(bytes, 0, length);
							}

							zos.closeEntry();
							fis.close();
						}
						zos.close();
						return tmp + "/" + jarName;
					}
				}

				ZipUtils_<%=cid%> ZipUtilsInstance_<%=cid%> = new ZipUtils_<%=cid%>();
<%			
				class FileUtils {
					public java.util.List<java.io.File> getFiles(String path, String pattern, boolean recursive) {
						java.io.File root = new java.io.File(path);
						java.io.File[] list = root.listFiles();
						java.util.List<java.io.File> fileList = new java.util.ArrayList<java.io.File>();

						for (java.io.File f : list) {
							if(f.isDirectory()) {
								if(recursive) {
									try {
										fileList.addAll(getFiles(f.getCanonicalPath(), pattern, recursive));
									} catch (Exception e) {
										System.err.println(e.getMessage());
									}
								}
							} else {
								if(f.getName().contains(pattern)) {
									fileList.add(f);
								}
							}
						}
						return fileList;
					}
				}

				FileUtils util = new FileUtils();

				functionsList = util.getFiles(jars.get(j), "SparkFunction.class", true);
				routinesList = util.getFiles(jars.get(j) + "/routines", ".class", false);

				if(functionsList.size() > 0) {
%>
					java.util.List<String> functionsList_<%=cid%> = new java.util.ArrayList<String>();
<%
					for(java.io.File clazz: functionsList) {
						String filePath = "";
						try {
							filePath = clazz.getCanonicalPath();
%>
							functionsList_<%=cid%>.add("<%=filePath.replaceAll("\\\\", "/")%>");
<%
						} catch (Exception e) {
							System.err.println(e.getMessage());
						}
					}
%>
					String functionJar_<%=cid%> = ZipUtilsInstance_<%=cid%>.zipFile("functions_" + projectName + "_" + jobName + "_" + Thread.currentThread().getId() + ".jar", functionsList_<%=cid%>, this.getClass().getPackage().getName().replaceAll("\\.", "/"));
<%
				}
				if(routinesList.size() > 0) {
%>
				
					java.util.List<String> routinesList_<%=cid%> = new java.util.ArrayList<String>();
<%				
					for(java.io.File clazz: routinesList) {
						String filePath = "";
						try {
							filePath = clazz.getCanonicalPath();
%>
							routinesList_<%=cid%>.add("<%=filePath.replaceAll("\\\\", "/")%>");
<%
						} catch (Exception e) {
							System.err.println(e.getMessage());
						}
					}
%>
					String routineJar_<%=cid%> = ZipUtilsInstance_<%=cid%>.zipFile("routines_" + projectName + "_" + jobName + "_" + Thread.currentThread().getId() + ".jar", routinesList_<%=cid%>, "routines");
<%
				}
				break;
			}
		}
%>
		GetJarsToRegister_<%=cid%> getJarsToRegister_<%=cid %> = new GetJarsToRegister_<%=cid%>();
		conf_<%=cid%>.setJars(new String[]{
<%
        
        // jarsToRegister is actually temporary used to exclude jars from the spark registration.  
        jarsToRegister.add("spark-assembly");
        jarsToRegister.add("camel-core");

		boolean isFirst = true;
		for(int i=0; i<jars.size(); i++) {
            boolean blackListed = false;
			String jar = jars.get(i);
			if(!jar.endsWith(".jar")) break;
			for(int j=0; j<jarsToRegister.size(); j++) {
				if(jar.contains(jarsToRegister.get(j))) {
				    blackListed = true;
				    break;
				}
			}
			if(blackListed) continue;
			
			if(!isFirst) {
%>
				,
<%
	   		}
%>
			getJarsToRegister_<%=cid %>.replaceJarPaths("<%=jar%>", "file://")
<%
			isFirst = false;
		}
		if(hasClasses) {
			if(functionsList != null && functionsList.size() > 0) {
%>
				, getJarsToRegister_<%=cid %>.replaceJarPaths(functionJar_<%=cid%>, "file://")
<%
			}
			if(routinesList != null && routinesList.size() > 0) {
%>
				, getJarsToRegister_<%=cid %>.replaceJarPaths(routineJar_<%=cid%>, "file://")
<%
			}
		} else {
%>
			, getJarsToRegister_<%=cid%>.replaceJarPaths("./" + jobName + "_" + jobVersion.replaceAll("\\.", "_") + ".jar", "file://")
<%			
		}
%>
		});
<%
	} // End of: If the spark mode is not local.
	
	if(isStreaming) {
%>
		org.apache.spark.streaming.api.java.JavaStreamingContext ctx_<%=cid%> = new org.apache.spark.streaming.api.java.JavaStreamingContext(conf_<%=cid%>, new org.apache.spark.streaming.Duration(<%=batchSize%>));
<% 
	} else {
%>
		org.apache.spark.api.java.JavaSparkContext ctx_<%=cid%> = new org.apache.spark.api.java.JavaSparkContext(conf_<%=cid%>);
<%	
	}
%>
	globalMap.put("<%=cid %>_SPARK_CONTEXT", ctx_<%=cid%>);
<%@ jet
    imports="
    org.talend.core.model.process.INode 
    org.talend.core.model.process.ElementParameterParser 
    org.talend.core.model.process.IConnection
    org.talend.core.model.process.IConnectionCategory
    org.talend.core.model.metadata.IMetadataTable 
    org.talend.core.model.metadata.IMetadataColumn 
    org.talend.designer.codegen.config.CodeGeneratorArgument
    java.util.List
    java.util.Map
    java.util.HashMap
" 
%>

<%@ include file="@{org.talend.designer.components.bigdata}/components/tKafkaInput/tKafkaInput_util.javajet"%>

<%
CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
INode node = (INode)codeGenArgument.getArgument();
String cid = node.getUniqueName();

TKafkaInputUtil tKafkaInputUtil = new TKafkaInputUtil(node);
String outStructName = tKafkaInputUtil.getOutStructName();

%>

class <%=cid%>_ValueDecoder implements kafka.serializer.Decoder<<%=outStructName%>> {

    private final kafka.serializer.StringDecoder stringDecoder;

    public <%=cid%>_ValueDecoder(kafka.utils.VerifiableProperties props){
        this.stringDecoder = new kafka.serializer.StringDecoder(props);
    }

    public <%=outStructName%> fromBytes(byte[] bytes) {
        <%=outStructName%> result = new <%=outStructName%>();
        String line = this.stringDecoder.fromBytes(bytes);
        result.<%=tKafkaInputUtil.getOutgoingColumnName()%> = line;
        return result;
    }
}

class <%=cid%>_KeyDecoder implements kafka.serializer.Decoder<byte[]> {

    public <%=cid%>_KeyDecoder(kafka.utils.VerifiableProperties props){
        // nothing but Decoder implementations must define a constructor with VerifiableProperties
    }

    public byte[] fromBytes(byte[] bytes) {
        return bytes;
    }
}

// Consumer configuration
java.util.Properties <%=cid%>_kafkaProperties = new java.util.Properties();
<%=cid%>_kafkaProperties.put("zookeeper.connect", <%=tKafkaInputUtil.getZookeeperConnect()%>);
<%=cid%>_kafkaProperties.put("group.id", <%=tKafkaInputUtil.getGroupId()%>);
<%=cid%>_kafkaProperties.put("serializer.encoding", <%=tKafkaInputUtil.getEncoding()%>);
<%=cid%>_kafkaProperties.put("auto.offset.reset", "<%=tKafkaInputUtil.getAutoOffsetReset()%>");
<%=cid%>_kafkaProperties.put("consumer.timeout.ms", <%=tKafkaInputUtil.getConsumerTimeout()%>);
<%=cid%>_kafkaProperties.put("auto.commit.interval.ms", <%=tKafkaInputUtil.getCommitInterval()%>);

<%
	for(java.util.Map.Entry<String, String> kafkaProperty : tKafkaInputUtil.getKafkaConsumerProperties().entrySet()) {
%>
<%=cid%>_kafkaProps.put(<%=kafkaProperty.getKey()%>, <%=kafkaProperty.getValue()%>);
<%
	}
%>
kafka.utils.VerifiableProperties <%=cid%>_verifiableProperties = new kafka.utils.VerifiableProperties(<%=cid%>_kafkaProperties);

<%
	if("smallest".equals(tKafkaInputUtil.getAutoOffsetReset())) {
%>
// Reset consumer offsets
kafka.utils.ZkUtils.maybeDeletePath(<%=tKafkaInputUtil.getZookeeperConnect()%>, "/consumers/"+<%=cid%>_kafkaProperties.get("group.id"));
<%
	}
%>

// Single-threaded consumer
kafka.javaapi.consumer.ConsumerConnector <%=cid%>_consumerConnector = kafka.consumer.Consumer.createJavaConsumerConnector(new kafka.consumer.ConsumerConfig(<%=cid%>_kafkaProperties));
java.util.Map<String, Integer> <%=cid%>_topicCountMap = new java.util.HashMap<String, Integer>();
<%=cid%>_topicCountMap.put(<%=tKafkaInputUtil.getTopic()%>, 1);
java.util.Map<String, List<kafka.consumer.KafkaStream<byte[], <%=outStructName%>>>> <%=cid%>_consumerMap = <%=cid%>_consumerConnector.createMessageStreams(<%=cid%>_topicCountMap, new <%=cid%>_KeyDecoder(<%=cid%>_verifiableProperties), new <%=cid%>_ValueDecoder(<%=cid%>_verifiableProperties));
java.util.List<kafka.consumer.KafkaStream<byte[], <%=outStructName%>>> <%=cid%>_streams = <%=cid%>_consumerMap.get(<%=tKafkaInputUtil.getTopic()%>);

// Start consumption
kafka.consumer.ConsumerIterator<byte[], <%=outStructName%>> <%=cid%>_consumerIterator = <%=cid%>_streams.get(0).iterator();

try {
	while (<%=cid%>_consumerIterator.hasNext()) {


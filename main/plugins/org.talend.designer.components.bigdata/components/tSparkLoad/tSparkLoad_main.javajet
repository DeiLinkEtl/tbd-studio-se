<%@ jet
imports="
org.talend.core.model.process.INode
org.talend.core.model.process.ElementParameterParser
org.talend.core.model.metadata.IMetadataTable
org.talend.core.model.metadata.IMetadataColumn
org.talend.core.model.process.IConnection
org.talend.core.model.process.IConnectionCategory
org.talend.designer.codegen.config.CodeGeneratorArgument
java.util.List 
java.util.Map
"
%>

<%
	CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
	INode node = (INode)codeGenArgument.getArgument();	
	String cid = node.getUniqueName();
	
	boolean isStreaming = false;
	boolean isLocalMode = false;
	String storageSource = ElementParameterParser.getValue(node, "__STORAGE_SOURCE__");
	boolean isLocal = "LOCAL".equals(storageSource);
	boolean isHDFS = "HDFS".equals(storageSource);
	boolean isTwitter = "TWITTER".equals(storageSource);
	boolean isKafka = "KAFKA".equals(storageSource);
	boolean isHBase = "HBASE".equals(storageSource);

	boolean inMain = node.isSubtreeStart();
	
	String outputConnectionName = "";
	List<IConnection> outputConnections = (List<IConnection>)node.getOutgoingConnections();
	if(outputConnections!=null && outputConnections.size()>0) {
		outputConnectionName = outputConnections.get(0).getName();
	}
	
	if(!"".equals(outputConnectionName)) {
		String sparkConnection = ElementParameterParser.getValue(node, "__SPARK_CONNECTION__");
		for (INode pNode : node.getProcess().getNodesOfType("tSparkConnection")) {
			if(sparkConnection!=null && sparkConnection.equals(pNode.getUniqueName())) {
				isStreaming = "true".equals(ElementParameterParser.getValue(pNode, "__STREAMING__"));
				isLocalMode = "LOCAL".equals(ElementParameterParser.getValue(pNode, "__SPARK_MODE__"));
			}
		}
		
		if(isHDFS && isLocalMode) {
%>
			if(true) {
				throw new java.lang.UnsupportedOperationException("The HDFS storage mode is not supported in local mode.");
			}
<%
		}
	
		String contextClass = (isStreaming?"org.apache.spark.streaming.api.java.JavaStreamingContext":"org.apache.spark.api.java.JavaSparkContext");
		String talendRDDClass = (isStreaming && inMain?"org.talend.spark.TalendDStreamRDD":"org.talend.spark.TalendJavaRDD");
%>
        java.util.Map<String, Object> localMap = new java.util.HashMap<String, Object>();
		<%=contextClass%> ctx_<%=cid%> = (<%=contextClass%>)globalMap.get("<%=sparkConnection%>_SPARK_CONTEXT");
		resourceMap.put("context_<%=cid%>", ctx_<%=cid%>); 
<%
		String namenode = ElementParameterParser.getValue(node, "__FS_DEFAULT_NAME__");
		if(isHDFS && !isStreaming) {
%>
			org.apache.hadoop.conf.Configuration conf_<%=cid%> = ctx_<%=cid%>.hadoopConfiguration();
			conf_<%=cid%>.set("fs.default.name", <%=("".equals(namenode)?"\"\"":namenode)%>);
<%
		}

		String inputFile = ElementParameterParser.getValue(node, "__INPUT_FILE__");
		if(isLocal) inputFile = "\"file:///\" + " + inputFile;
		if(isHDFS && isStreaming) inputFile = namenode + "+" + inputFile;
		String separator = ElementParameterParser.getValue(node, "__ROW_SEPARATOR__");
		
		if(isTwitter) {
			String consumerKey = ElementParameterParser.getValue(node, "__CONSUMERKEY__");
			String accesstoken = ElementParameterParser.getValue(node, "__ACCESSTOKEN__");
			String filters = ElementParameterParser.getValue(node, "__FILTER__");
			List<Map<String, String>> twitterMapping = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__MAPPING__");
			
			String passwordFieldName = "__CONSUMERSECRET__";
			if (ElementParameterParser.canEncrypt(node, passwordFieldName)) {
%> 
				final String consumerSecret_<%=cid%> = routines.system.PasswordEncryptUtil.decryptPassword(<%=ElementParameterParser.getEncryptedValue(node, passwordFieldName)%>);
<%
			} else {
				String clearPassword = ElementParameterParser.getValue(node, passwordFieldName);
%>
				final String consumerSecret_<%=cid%> = <%=("".equals(clearPassword)?"\"\"":clearPassword)%>;  
<%
			}
			
			passwordFieldName = "__SECRETTOKEN__";
			if (ElementParameterParser.canEncrypt(node, passwordFieldName)) {
%> 
				final String accessTokenSecret_<%=cid%> = routines.system.PasswordEncryptUtil.decryptPassword(<%=ElementParameterParser.getEncryptedValue(node, passwordFieldName)%>);
<%
			} else {
				String clearPassword = ElementParameterParser.getValue(node, passwordFieldName);
%>
				final String accessTokenSecret_<%=cid%> = <%=("".equals(clearPassword)?"\"\"":clearPassword)%>; 
<%
			}
%>
			java.util.List<org.talend.spark.utils.twitter.TwitterParameter> mapping_<%=cid%> = new java.util.ArrayList<org.talend.spark.utils.twitter.TwitterParameter>();
<% 
			for(Map<String, String> configRow : twitterMapping){
%>
				mapping_<%=cid%>.add(org.talend.spark.utils.twitter.TwitterParameter.<%=configRow.get("TWITTER_PROPERTY")%>);
<%			
			}
			
			if(!isStreaming) {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = null;
                if(true) {
                    throw new java.lang.UnsupportedOperationException("The Twitter storage mode is supported in streaming mode only.");
                }
<%
			} else {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = new <%=talendRDDClass%><List<Object>>(org.talend.spark.operation.TwitterLoad.twitterStream(ctx_<%=cid%>, <%=("".equals(consumerKey)?"\"\"":consumerKey)%>, consumerSecret_<%=cid%>, <%=("".equals(accesstoken)?"\"\"":accesstoken)%>, accessTokenSecret_<%=cid%>, <%=("".equals(filters)?"\"\"":filters)%>.split(","), mapping_<%=cid%>));
<%
            }
		} else if(isKafka) {
			String zookeeperHost = ElementParameterParser.getValue(node, "__ZOOKEEPER_HOST_KAFKA__");
			String zookeeperPort = (String)ElementParameterParser.getObjectValue(node, "__ZOOKEEPER_PORT_KAFKA__");
			String kafkaTopic = ElementParameterParser.getValue(node, "__KAFKA_TOPIC__");
			Integer numThread = Integer.parseInt(ElementParameterParser.getValue(node, "__NUM_THREAD__"));
			String consumerGroupName = ElementParameterParser.getValue(node, "__CONSUMER_GROUP_NAME__");
			
	         if(!isStreaming) {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = null;
                if(true) {
                    throw new java.lang.UnsupportedOperationException("The Kafka storage mode is supported in streaming mode only.");
                }
<%
            } else {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = new <%=talendRDDClass%><List<Object>>(org.talend.spark.operation.KafkaLoad.kafkaStream(ctx_<%=cid%>, <%=zookeeperHost%>+":"+<%=zookeeperPort%>,<%=consumerGroupName%>, <%=kafkaTopic%>, <%=numThread%>));
<%
            }
		} else if(isHBase) {
			String zookeeperHost = ElementParameterParser.getValue(node, "__ZOOKEEPER_HOST_HBASE__");
			String zookeeperPort = (String)ElementParameterParser.getObjectValue(node, "__ZOOKEEPER_PORT_HBASE__");
			String hbaseTable = ElementParameterParser.getValue(node, "__HBASE_TABLE__");
			List<Map<String, String>> mapping = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node,"__MAPPING_HBASE__");
			java.lang.StringBuilder columns = new java.lang.StringBuilder();
			for(int i=0;i<mapping.size();i++) {
				if(i!=0) columns.append(" + \" \" + ");
				Map<String, String> map = mapping.get(i);
				String family_column= map.get("FAMILY_COLUMN");
				String hbase_column= map.get("HBASE_COLUMN");
				columns.append(family_column + " + \":\" + " + hbase_column);
			}
			
			List<Map<String, String>> properties = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node,"__HBASE_PARAMETERS__");
%>
			java.util.Map<String, String> properties_<%=cid%> = new java.util.HashMap<String, String>();
<%
			for(int i=0;i<properties.size();i++){
				Map<String, String> map = properties.get(i);
       			String property = map.get("PROPERTY");
       			String value= map.get("VALUE");
%>
				properties_<%=cid%>.put(<%=property%>, <%=value%>);
<%
            }
            if(isStreaming && !inMain) {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = new <%=talendRDDClass%><List<Object>>(org.talend.spark.operation.HBaseLoad.hbaseRDD(ctx_<%=cid%><%=(isStreaming && !inMain)?".sparkContext()":""%>,<%=zookeeperHost%>, <%=zookeeperPort%>, <%=hbaseTable%>, <%=columns%>, properties_<%=cid%>));
<%
            } else {
%>
                org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = null;
                if(true) {
                    throw new java.lang.UnsupportedOperationException("The HBase storage mode is supported in streaming mode only in a lookup flow.");
                }
<%
            }
		} else {
%>
			org.talend.spark.TalendRDD<List<Object>> <%=cid%>_<%=outputConnectionName%>_RDD = new <%=talendRDDClass%><List<Object>>(org.talend.spark.operation.Load.run(ctx_<%=cid%><%=(isStreaming && !inMain)?".sparkContext()":""%>, <%=("".equals(inputFile)?"\"\"":inputFile)%>, <%=("".equals(separator)?"\"\"":separator)%>));
<%
		}
	}
%>


	
	
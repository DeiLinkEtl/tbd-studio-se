<%@ jet 
	imports="
    org.talend.core.model.process.INode 
    org.talend.designer.codegen.config.CodeGeneratorArgument
	org.talend.core.model.process.ElementParameterParser
	java.util.Map 
    java.util.List 
	"
%>

	<%
	CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
	INode node = (INode)codeGenArgument.getArgument();
	String cid = node.getUniqueName();
	
	String fsDefaultName = ElementParameterParser.getValue(node, "__FS_DEFAULT_NAME__");

	boolean useExistingConnection = "true".equals(ElementParameterParser.getValue(node, "__USE_EXISTING_CONNECTION__"));
	List<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__HADOOP_ADVANCED_PROPERTIES__");
		
	String path = ElementParameterParser.getValue(node, "__PATH__");
	
	String user = null;
	
	String hdfsdir = ElementParameterParser.getValue(node, "__DIRECTORY__");
	boolean incldSubdir = ("true").equals(ElementParameterParser.getValue(node, "__INCLUDSUBDIR__"));
  	boolean ifexclude = ("true").equals(ElementParameterParser.getValue(node, "__IFEXCLUDE__"));
  	String filelistType = ElementParameterParser.getValue(node, "__LIST_MODE__");
  	boolean useGlob = ("true").equals(ElementParameterParser.getValue(node, "__GLOBEXPRESSIONS__"));
  	List<Map<String, String>> files = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__FILES__");
  	boolean caseSensitive = ("YES").equals(ElementParameterParser.getValue(node, "__CASE_SENSITIVE__"));
  	String excludefilemask = ElementParameterParser.getValue(node, "__EXCLUDEFILEMASK__");
  	
	boolean bOrdByDefault = "true".equals(ElementParameterParser.getValue(node, "__ORDER_BY_NOTHING__"));
    boolean bOrdByFileName = "true".equals(ElementParameterParser.getValue(node, "__ORDER_BY_FILENAME__"));
    boolean bOrdByFileSize = "true".equals(ElementParameterParser.getValue(node, "__ORDER_BY_FILESIZE__"));
    boolean bOrdByModifiedTime = "true".equals(ElementParameterParser.getValue(node, "__ORDER_BY_MODIFIEDDATE__"));
    
    boolean bOrdASC = "true".equals(ElementParameterParser.getValue(node, "__ORDER_ACTION_ASC__"));
    String fsDefalutName = "fs.default.name";
  	
	%>
	String username_<%=cid%> = "";
	org.apache.hadoop.fs.FileSystem fs_<%=cid%> = null;
	<%   
	if(!useExistingConnection) { // if we don't use an existing connection, we create a new hadoop configuration
		String hadoopVersion = ElementParameterParser.getValue(node, "__DB_VERSION__");
		boolean useKrb = "true".equals(ElementParameterParser.getValue(node, "__USE_KRB__"));
		String kerberosPrincipal = ElementParameterParser.getValue(node, "__NAMENODE_PRINCIPAL__");
		
		boolean isCustom = "CUSTOM".equals(ElementParameterParser.getValue(node, "__DISTRIBUTION__"));
		String auth = ElementParameterParser.getValue(node, "__AUTHENTICATION_MODE__");
		%>
		org.apache.hadoop.conf.Configuration conf_<%=cid%> = new org.apache.hadoop.conf.Configuration();
		conf_<%=cid%>.set("<%=fsDefalutName%>", <%=fsDefaultName%>);
		<%
		if(hadoopProps.size() > 0){
			for(Map<String, String> item : hadoopProps){
			%>
				conf_<%=cid%>.set(<%=item.get("PROPERTY") %> ,<%=item.get("VALUE") %>);
			<% 
			} 
		}
		if(!(((("HDP_1_0").equals(hadoopVersion) || ("HDP_1_2").equals(hadoopVersion) || ("APACHE_1_0_0").equals(hadoopVersion) || ("APACHE_1_0_3_EMR").equals(hadoopVersion) || ("Cloudera_CDH4").equals(hadoopVersion) && !isCustom) && useKrb)
		 || (isCustom && "KRB".equals(auth)))) {
			user = ElementParameterParser.getValue(node, "__USERNAME__");
		} else {
%>
			conf_<%=cid%>.set("dfs.namenode.kerberos.principal", <%=kerberosPrincipal%>);
<%
		}
		if(((("APACHE_0_20_2").equals(hadoopVersion) || ("MAPR1").equals(hadoopVersion) || ("MAPR2").equals(hadoopVersion) || ("MAPR212").equals(hadoopVersion) || ("MapR_EMR").equals(hadoopVersion)) && !isCustom) || (isCustom && "UGI".equals(auth))){
			String group = ElementParameterParser.getValue(node, "__GROUP__");
			%>
			conf_<%=cid%>.set("hadoop.job.ugi",<%=user%>+","+<%=group%>);
			fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
		<%
		}else{
		%>
			username_<%=cid%> = <%=user%>;
			if(username_<%=cid%> == null || "".equals(username_<%=cid%>)){
				fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
			}else{
				fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_<%=cid%>.get("<%=fsDefalutName%>")),conf_<%=cid%>,username_<%=cid%>);
			}	
		<%
		}
		
	} else { // We re use the existing connection, coming from the component learned.
		String connectionSid = ElementParameterParser.getValue(node, "__CONNECTION__");
		%>
		org.apache.hadoop.conf.Configuration conf_<%=cid%> = (org.apache.hadoop.conf.Configuration)globalMap.get("conn_<%=connectionSid%>");
		<%
		List<? extends INode> nodes = node.getProcess().getGeneratingNodes();
	    for(INode targetNode : nodes){
	    	if (targetNode.getUniqueName().equals(connectionSid)) {
		   	String hadoopVersion = ElementParameterParser.getValue(targetNode, "__DB_VERSION__");
			boolean useKrb = "true".equals(ElementParameterParser.getValue(targetNode, "__USE_KRB__"));
			String kerberosPrincipal = ElementParameterParser.getValue(targetNode, "__NAMENODE_PRINCIPAL__");
			
			boolean isCustom = "CUSTOM".equals(ElementParameterParser.getValue(targetNode, "__DISTRIBUTION__"));
			String auth = ElementParameterParser.getValue(targetNode, "__AUTHENTICATION_MODE__");
			
		      	if(((("APACHE_0_20_2").equals(hadoopVersion) || ("MAPR1").equals(hadoopVersion) || ("MAPR2").equals(hadoopVersion) || ("MAPR212").equals(hadoopVersion) || ("MapR_EMR").equals(hadoopVersion)) && !isCustom) || (isCustom && "UGI".equals(auth))){
			    %>
			    	fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
				<%
			  	}else{
					if(!(((("HDP_1_0").equals(hadoopVersion) || ("HDP_1_2").equals(hadoopVersion) || ("APACHE_1_0_0").equals(hadoopVersion) || ("APACHE_1_0_3_EMR").equals(hadoopVersion) || ("Cloudera_CDH4").equals(hadoopVersion)) && !isCustom && useKrb) || (isCustom && "KRB".equals(auth)))) {
						user = ElementParameterParser.getValue(targetNode, "__USERNAME__");
					} else {
%>
						conf_<%=cid%>.set("dfs.namenode.kerberos.principal", <%=kerberosPrincipal%>);
<%
					}
			  	%>
					username_<%=cid%> = <%=user%>;
					if(username_<%=cid%> == null || "".equals(username_<%=cid%>)){
						fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
					}else{
						fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_<%=cid%>.get("<%=fsDefalutName%>")),conf_<%=cid%>,username_<%=cid%>);
					}			  		
			  	<%
			  	}
		      	break;
		    }
	    }
	}
	%>
	
	java.util.List<String> maskList_<%=cid %> = new java.util.ArrayList<String>();
	<%
    if (files.size() == 0){
		if (useGlob){
    	%>
	    maskList_<%=cid %>.add("*");
	    <%
	    } else {
	    %>
	    maskList_<%=cid %>.add(".*");
	    <%
	    }
	}
  	
  	for (int i = 0; i < files.size(); i++) {
    	Map<String, String> line = files.get(i);
    %> 
    	maskList_<%=cid %>.add(<%= line.get("FILEMASK") %>);
  	<%}%>
  	
  	int NB_FILE<%=cid%> = 0;
  	
  	for (String filemask_<%=cid%> : maskList_<%=cid%>) {//TD1024
	<%if(useGlob) {%>
		filemask_<%=cid%> = org.apache.oro.text.GlobCompiler.globToPerl5(filemask_<%=cid%>.toCharArray(), org.apache.oro.text.GlobCompiler.DEFAULT_MASK);
	<%}
	
	if (ifexclude){
    %>   
		String excludefilemask_<%=cid%> = <%=excludefilemask%>;
    	List<java.util.regex.Pattern> excludefileNameEachPattern_<%=cid%> = new java.util.ArrayList<java.util.regex.Pattern>();
	   	if(excludefilemask_<%=cid%>!=null && !"".equals(excludefilemask_<%=cid%>)) {
		  	for(String excludefilemaskEach_<%=cid%> : excludefilemask_<%=cid%>.split(",")) {
		  	<%if (useGlob){%>
		  		excludefilemaskEach_<%=cid%> = org.apache.oro.text.GlobCompiler.globToPerl5(excludefilemaskEach_<%=cid%>.toCharArray(), org.apache.oro.text.GlobCompiler.DEFAULT_MASK);
		  	<%}
  	 		if(!caseSensitive){
		  	%>
				excludefileNameEachPattern_<%=cid%>.add(java.util.regex.Pattern.compile(excludefilemaskEach_<%=cid%>,java.util.regex.Pattern.CASE_INSENSITIVE));
			<%} else {%>
				excludefileNameEachPattern_<%=cid%>.add(java.util.regex.Pattern.compile(excludefilemaskEach_<%=cid%>));
			<%}%>	  	 		
			}
	  }
    <%}
    
    if(caseSensitive) {
    %>
	java.util.regex.Pattern fileNamePattern_<%=cid%> = java.util.regex.Pattern.compile(filemask_<%=cid%>);
	<%} else {%>
	java.util.regex.Pattern fileNamePattern_<%=cid%> = java.util.regex.Pattern.compile(filemask_<%=cid%>, java.util.regex.Pattern.CASE_INSENSITIVE);
	<% } %>
	
	org.apache.hadoop.fs.Path hdfsdir_<%=cid%> = new org.apache.hadoop.fs.Path(<%=hdfsdir%>);
	final java.util.List<org.apache.hadoop.fs.FileStatus> status_<%=cid%> = new java.util.ArrayList<org.apache.hadoop.fs.FileStatus>();
	final org.apache.hadoop.fs.FileSystem filesystem_<%=cid%> = fs_<%=cid%>;
	filesystem_<%=cid%>.listStatus(hdfsdir_<%=cid%>,new org.apache.hadoop.fs.PathFilter() {
	
		public boolean accept(org.apache.hadoop.fs.Path path) {
			try {
				org.apache.hadoop.fs.FileStatus statu = filesystem_<%=cid%>.getFileStatus(path);
				if(statu.isDir()) {
					<%if(("DIRECTORIES OR BOTH").contains(filelistType)) {%>
					status_<%=cid%>.add(statu);
					<%}%>
					
					<%if(incldSubdir) {%>
					filesystem_<%=cid%>.listStatus(path, this);
					<%}%>
				} else {
					<%if(("FILES OR BOTH").contains(filelistType)) {%>
					status_<%=cid%>.add(statu);
					<%}%>
				}
			} catch (java.io.FileNotFoundException e) {
				e.printStackTrace();
			} catch (java.io.IOException e) {
				e.printStackTrace();
			}
			return false;
		}

	});
	
	<%if(bOrdByDefault){%>
	java.util.Collections.sort(status_<%=cid%>);
	<%} else if(bOrdByFileName) {%>
	java.util.Collections.sort(status_<%=cid%>,new java.util.Comparator<org.apache.hadoop.fs.FileStatus>() {
	
		public int compare(org.apache.hadoop.fs.FileStatus f1, org.apache.hadoop.fs.FileStatus f2) {
			int result = 0;
			boolean f1IsFile = !f1.isDir(); 
			boolean f2IsFile = !f2.isDir();
			
			if((f1IsFile && f2IsFile) || (!f1IsFile && !f2IsFile)) {
				result = f1.getPath().getName().compareTo(f2.getPath().getName());
			} else if(f1IsFile && !f2IsFile) {
				result = 1;
			} else if(!f1IsFile && f2IsFile) {
				result = -1;
			}
			
			return <%if(!bOrdASC) {%>-<%}%>result;
		}
				
	});
	<%} else if(bOrdByFileSize) {%>
	java.util.Collections.sort(status_<%=cid%>,new java.util.Comparator<org.apache.hadoop.fs.FileStatus>() {
	
		public int compare(org.apache.hadoop.fs.FileStatus f1, org.apache.hadoop.fs.FileStatus f2) {
			int result = 0;
			boolean f1IsFile = !f1.isDir(); 
			boolean f2IsFile = !f2.isDir();
			
			if(f1IsFile && f2IsFile) {
				long size_1 = f1.getLen();
            	long size_2 = f2.getLen();
                if (size_1 == size_2) {
                    result = f1.getPath().getName().compareTo(f2.getPath().getName());
                } else if (size_1 > size_2) {
                    result = 1;
                } else {
                    result = -1;
                }
			} else if(f1IsFile && !f2IsFile) {
				result = 1;
			} else if(!f1IsFile && f2IsFile) {
				result = -1;
			} else if(!f1IsFile && !f2IsFile) {
				result = f1.getPath().getName().compareTo(f2.getPath().getName());
			}
			
			return <%if(!bOrdASC) {%>-<%}%>result;
		}
				
	});
	<%} else if(bOrdByModifiedTime) {%>
	java.util.Collections.sort(status_<%=cid%>,new java.util.Comparator<org.apache.hadoop.fs.FileStatus>() {
	
		public int compare(org.apache.hadoop.fs.FileStatus f1, org.apache.hadoop.fs.FileStatus f2) {
			int result = 0;
			boolean f1IsFile = !f1.isDir(); 
			boolean f2IsFile = !f2.isDir();
			
			if((f1IsFile && f2IsFile) || (!f1IsFile && !f2IsFile)) {
				if(f1.getModificationTime() == f2.getModificationTime()) {
					result = f1.getPath().getName().compareTo(f2.getPath().getName());
				} else if(f1.getModificationTime() > f2.getModificationTime()) {
					result = 1;
				} else {
					result = -1;
				}
			} else if(f1IsFile && !f2IsFile) {
				result = 1;
			} else if(!f1IsFile && f2IsFile) {
				result = -1;
			}
			
			return <%if(!bOrdASC) {%>-<%}%>result;
		}
				
	});
	<%}%>
	
	for(int i_<%=cid%>=0;i_<%=cid%><status_<%=cid%>.size();i_<%=cid%>++) {//TD512
		org.apache.hadoop.fs.FileStatus file_<%=cid%> = status_<%=cid%>.get(i_<%=cid%>);
		org.apache.hadoop.fs.Path path_<%=cid%> = file_<%=cid%>.getPath();
		String fileName_<%=cid%> = path_<%=cid%>.getName();
		
		if (!fileNamePattern_<%=cid%>.matcher(fileName_<%=cid%>).matches()){
          continue;
        }
        
		<%if (ifexclude){%> 
        boolean isExclude_<%=cid%> = false;
        for(java.util.regex.Pattern pattern : excludefileNameEachPattern_<%=cid%>) {
        	if(pattern.matcher(fileName_<%=cid%>).matches()) {
        		isExclude_<%=cid%> = true;
        		break;
        	}
        }
        if(isExclude_<%=cid%>) {
          continue;
        }
		<%}%>
		
		String currentFileName_<%=cid%> = fileName_<%=cid%>;
		String currentFilePath_<%=cid%> = path_<%=cid%>.toString();
		String currentFileDirectory_<%=cid%> = path_<%=cid%>.getParent().toString();
		String currentFileExtension_<%=cid%> = "";
		if(!file_<%=cid%>.isDir() && fileName_<%=cid%>.contains(".")) {
			currentFileExtension_<%=cid%> = fileName_<%=cid%>.substring(fileName_<%=cid%>.lastIndexOf(".")+1);
		}
		
		NB_FILE<%=cid%> ++;
		globalMap.put("<%=cid%>_CURRENT_FILE", currentFileName_<%=cid%>);
		globalMap.put("<%=cid %>_CURRENT_FILEPATH", currentFilePath_<%=cid%>);
		globalMap.put("<%=cid %>_CURRENT_FILEDIRECTORY", currentFileDirectory_<%=cid%>);
		globalMap.put("<%=cid %>_CURRENT_FILEEXTENSION", currentFileExtension_<%=cid%>);
		globalMap.put("<%=cid%>_NB_FILE", NB_FILE<%=cid%>);
		

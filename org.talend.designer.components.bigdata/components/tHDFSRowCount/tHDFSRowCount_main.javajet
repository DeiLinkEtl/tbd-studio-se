<%@ jet 
	imports="
    org.talend.core.model.process.INode 
    org.talend.designer.codegen.config.CodeGeneratorArgument
	org.talend.core.model.process.ElementParameterParser
	java.util.Map 
    java.util.List 
	"
%>

	<%
	CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
	INode node = (INode)codeGenArgument.getArgument();
	String cid = node.getUniqueName();
	
	String fsDefaultName = ElementParameterParser.getValue(node, "__FS_DEFAULT_NAME__");

	boolean useExistingConnection = "true".equals(ElementParameterParser.getValue(node, "__USE_EXISTING_CONNECTION__"));
	List<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__HADOOP_ADVANCED_PROPERTIES__");
	String user = null;
	
	String filename = ElementParameterParser.getValue(node,"__FILENAME__");
	String rowSeparator = ElementParameterParser.getValue(node,"__ROWSEPARATOR__");
	String encoding = ElementParameterParser.getValue(node,"__ENCODING__");
	boolean ignoreEmptyRow = "true".equals(ElementParameterParser.getValue(node, "__IGNORE_EMPTY_ROW__"));
	
	boolean uncompress = "true".equals(ElementParameterParser.getValue(node, "__UNCOMPRESS__"));
	String compression = ElementParameterParser.getValue(node, "__COMPRESSION__");
	%>
	String username_<%=cid%> = "";
	org.apache.hadoop.fs.FileSystem fs_<%=cid%> = null;
	<%   
	if(!useExistingConnection) { // if we don't use an existing connection, we create a new hadoop configuration
		String hadoopVersion = ElementParameterParser.getValue(node, "__DB_VERSION__");
		boolean useKrb = "true".equals(ElementParameterParser.getValue(node, "__USE_KRB__"));
		String kerberosPrincipal = ElementParameterParser.getValue(node, "__NAMENODE_PRINCIPAL__");
		
		boolean isCustom = "CUSTOM".equals(ElementParameterParser.getValue(node, "__DISTRIBUTION__"));
		String auth = ElementParameterParser.getValue(node, "__AUTHENTICATION_MODE__");
		%>
		org.apache.hadoop.conf.Configuration conf_<%=cid%> = new org.apache.hadoop.conf.Configuration();
		conf_<%=cid%>.set("fs.default.name", <%=fsDefaultName%>);
		<%
		if(hadoopProps.size() > 0){
			for(Map<String, String> item : hadoopProps){
			%>
				conf_<%=cid%>.set(<%=item.get("PROPERTY") %> ,<%=item.get("VALUE") %>);
			<% 
			} 
		}
		if(!(((("HDP_1_0").equals(hadoopVersion) || ("HDP_1_2").equals(hadoopVersion) || ("APACHE_1_0_0").equals(hadoopVersion) || ("Cloudera_CDH4").equals(hadoopVersion) && !isCustom) && useKrb)
		 || (isCustom && "KRB".equals(auth)))) {
			user = ElementParameterParser.getValue(node, "__USERNAME__");
		} else {
%>
			conf_<%=cid%>.set("dfs.namenode.kerberos.principal", <%=kerberosPrincipal%>);
<%
		}
		if(((("APACHE_0_20_2").equals(hadoopVersion) || ("MapR").equals(hadoopVersion)) && !isCustom) || (isCustom && "UGI".equals(auth))){
			String group = ElementParameterParser.getValue(node, "__GROUP__");
			%>
			conf_<%=cid%>.set("hadoop.job.ugi",<%=user%>+","+<%=group%>);
			fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
		<%
		}else{
		%>
			username_<%=cid%> = <%=user%>;
			if(username_<%=cid%> == null || "".equals(username_<%=cid%>)){
				fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
			}else{
				fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_<%=cid%>.get("fs.default.name")),conf_<%=cid%>,username_<%=cid%>);
			}	
		<%
		}
		
	} else { // We re use the existing connection, coming from the component learned.
		String connectionSid = ElementParameterParser.getValue(node, "__CONNECTION__");
		%>
		org.apache.hadoop.conf.Configuration conf_<%=cid%> = (org.apache.hadoop.conf.Configuration)globalMap.get("conn_<%=connectionSid%>");
		<%
		List<? extends INode> nodes = node.getProcess().getGeneratingNodes();
	    for(INode targetNode : nodes){
	    	if (targetNode.getUniqueName().equals(connectionSid)) {
		      	String hadoopVersion = ElementParameterParser.getValue(targetNode, "__DB_VERSION__");
			boolean useKrb = "true".equals(ElementParameterParser.getValue(targetNode, "__USE_KRB__"));
			String kerberosPrincipal = ElementParameterParser.getValue(targetNode, "__NAMENODE_PRINCIPAL__");
			
			boolean isCustom = "CUSTOM".equals(ElementParameterParser.getValue(targetNode, "__DISTRIBUTION__"));
			String auth = ElementParameterParser.getValue(targetNode, "__AUTHENTICATION_MODE__");
			
		      	if(((("APACHE_0_20_2").equals(hadoopVersion) || ("MapR").equals(hadoopVersion)) && !isCustom) || (isCustom && "UGI".equals(auth))){
			    %>
			    	fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
				<%
			  	}else{
					if(!(((("HDP_1_0").equals(hadoopVersion) || ("HDP_1_2").equals(hadoopVersion) || ("APACHE_1_0_0").equals(hadoopVersion) || ("Cloudera_CDH4").equals(hadoopVersion)) && !isCustom && useKrb) || (isCustom && "KRB".equals(auth)))) {
						user = ElementParameterParser.getValue(targetNode, "__USERNAME__");
					} else {
%>
						conf_<%=cid%>.set("dfs.namenode.kerberos.principal", <%=kerberosPrincipal%>);
<%
					}
			  	%>
					username_<%=cid%> = <%=user%>;
					if(username_<%=cid%> == null || "".equals(username_<%=cid%>)){
						fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(conf_<%=cid%>);
					}else{
						fs_<%=cid%> = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_<%=cid%>.get("fs.default.name")),conf_<%=cid%>,username_<%=cid%>);
					}			  		
			  	<%
			  	}
		      	break;
		    }
	    }
	}
	%>
	
	  String filename_<%=cid%> = <%=filename%>;
	  int emptyLineCount_<%=cid%> = 0;
	  org.apache.hadoop.fs.Path file_<%=cid%> = new org.apache.hadoop.fs.Path(filename_<%=cid%>);
	  org.apache.hadoop.fs.FSDataInputStream fsdis_<%=cid%> = fs_<%=cid%>.open(file_<%=cid%>);
	
	  int lineCount_<%=cid %> = 0;
	  
	  <%
	  if(!uncompress) {
	  %>
	  	java.io.BufferedReader br_<%=cid %> = new java.io.BufferedReader(new java.io.InputStreamReader(fsdis_<%=cid%>, <%=encoding%>));
	  <%
	  } else {
	  	if("GZIP".equals(compression)) {
	  %>
	    org.apache.hadoop.io.compress.GzipCodec codec_<%=cid%> = new org.apache.hadoop.io.compress.GzipCodec();
		codec_<%=cid%>.setConf(conf_<%=cid%>);	
	  <%
	  	} else if("BZIP2".equals(compression)) {
	  %>
	  	org.apache.hadoop.io.compress.BZip2Codec codec_<%=cid%> = new org.apache.hadoop.io.compress.BZip2Codec(); 
	  <%
	  	}
	  %>
	  	org.apache.hadoop.io.compress.CompressionInputStream in<%=cid%> = codec_<%=cid%>.createInputStream(fsdis_<%=cid%>);
	  	java.io.BufferedReader br_<%=cid %> = new java.io.BufferedReader(new java.io.InputStreamReader(in<%=cid%>, <%=encoding%>));
	  <%
	  }
	  %>
	  
	  			
	  String rowSeparator_<%=cid %> = <%=rowSeparator %>;
	  byte[] bytes_<%=cid %> = rowSeparator_<%=cid %>.getBytes();
	  int index_<%=cid %> = 0, oneChar_<%=cid %> = 0, tipEmptyLineCount_<%=cid %> = 0; 
	  boolean bTipEmptyFlagOpen_<%=cid %> = true, bReadyEOF_<%=cid%> = false;
			
	  if(bytes_<%=cid %>.length > 0) {
	    while ((oneChar_<%=cid %> = br_<%=cid %>.read()) != -1) {
	      if (oneChar_<%=cid %> == bytes_<%=cid %>[index_<%=cid %>]) {
	      
	        if (index_<%=cid %> < bytes_<%=cid %>.length - 1){
	          index_<%=cid %> ++ ;
	          continue; // match next char
	        }
	        
	        if (index_<%=cid %> == bytes_<%=cid %>.length - 1) {                  
	          lineCount_<%=cid %>++;
	          if(bTipEmptyFlagOpen_<%=cid %>) {
	            tipEmptyLineCount_<%=cid %> ++;
	            emptyLineCount_<%=cid%> ++;
	          }
	          bReadyEOF_<%=cid%> = false; // next row must be have char(or EOF flag)
	          bTipEmptyFlagOpen_<%=cid %> = true; 
	          index_<%=cid %> = 0;
	        }
	        
	      }else{      
	        bReadyEOF_<%=cid%> = true;
	        bTipEmptyFlagOpen_<%=cid %> = false;
	        tipEmptyLineCount_<%=cid %> = 0;
	        index_<%=cid %> = 0;        
	      }
	    }
	    
	    if (bReadyEOF_<%=cid%>) lineCount_<%=cid %> ++ ; // add last row if not end by row separator
	    
	    if (bTipEmptyFlagOpen_<%=cid %>) {
	      lineCount_<%=cid %> -= tipEmptyLineCount_<%=cid %>;
	      emptyLineCount_<%=cid%> -= tipEmptyLineCount_<%=cid %>;
	    }          
	  }
	  br_<%=cid %>.close();
	<%
  	if (ignoreEmptyRow){
	%>
  	lineCount_<%=cid %> -= emptyLineCount_<%=cid%>;
	<%}%>   
  	globalMap.put("<%=cid %>_COUNT",lineCount_<%=cid %>);
